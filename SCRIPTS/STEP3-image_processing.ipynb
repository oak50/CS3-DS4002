{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we will process the images using transformations to get more data for each celebrity. We ultimately want 300 augmentied images for each celebrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed:\n",
    "\n",
    "pip install opencv-python\n",
    "\n",
    "pip install numpy\n",
    "\n",
    "pip install tensorflow\n",
    "\n",
    "pip install scipy\n",
    "\n",
    "pip install Pillow==10.2.0\n",
    "\n",
    "pip install facenet-pytorch\n",
    "\n",
    "\n",
    "## Installing LibGL library:\n",
    "\n",
    "### On Debian/Ubuntu-based Linux systems, run:\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install -y libgl1-mesa-glx\n",
    "\n",
    "### On CentOS/RHEL-based systems, run:\n",
    "\n",
    "sudo yum install mesa-libGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m  \u001b[38;5;66;03m# OpenCV for face detection\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, load_img, img_to_array, array_to_img\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set paths\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2  # OpenCV for face detection\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "# Set paths\n",
    "base_path = \"/workspace/DS4002Project3/DATA/celebrities\"  # Original dataset path\n",
    "extra_output_path = \"/workspace/DS4002Project3/DATA/celebrities_extra\"  # Folder for augmented images\n",
    "all_output_path = \"/workspace/DS4002Project3/DATA/celebrities_all\"  # Folder for final dataset\n",
    "\n",
    "# Set the path to the Haar cascade file for face detection\n",
    "haar_cascade_path = \"/workspace/DS4002Project3/DATA/haarcascade_frontalface_default.xml\"  # Update this path if needed\n",
    "\n",
    "# Clear output folders if they exist\n",
    "for path in [extra_output_path, all_output_path]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Data augmentation settings (generate exactly 5 versions per image)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Reduced rotation range\n",
    "    width_shift_range=0.1,  # Smaller width shift to avoid faces being cropped out\n",
    "    height_shift_range=0.1,  # Smaller height shift to avoid faces being cropped out\n",
    "    shear_range=0.2,  # Moderate shear\n",
    "    zoom_range=0.1,  # Zoom in slightly without cropping the face\n",
    "    horizontal_flip=True,  # Horizontal flip to add variation\n",
    "    fill_mode='nearest'  # Nearest mode to fill in pixels after transformations\n",
    ")\n",
    "\n",
    "# Function to check if a face is detected in an image using OpenCV\n",
    "def detect_face(image_path):\n",
    "    face_cascade = cv2.CascadeClassifier(haar_cascade_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    # Ensure at least one face is detected with reasonable size\n",
    "    for (x, y, w, h) in faces:\n",
    "        if w > 50 and h > 50:  # Only consider faces with a reasonable size\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Loop through each celebrity folder\n",
    "for celeb in os.listdir(base_path):\n",
    "    celeb_folder = os.path.join(base_path, celeb)\n",
    "    save_folder = os.path.join(extra_output_path, celeb)\n",
    "    os.makedirs(save_folder, exist_ok=True)  # Create sub-folder for each celebrity\n",
    "\n",
    "    # Detect images with .jpg, .jpeg, or .png extensions\n",
    "    images = [img for img in os.listdir(celeb_folder) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Initialize the image index to start from 1\n",
    "    image_index = 1\n",
    "\n",
    "    # Save the original images (index 1-100) and create augmented versions (index 101-400)\n",
    "    for image_name in images:\n",
    "        img_path = os.path.join(celeb_folder, image_name)\n",
    "        img = load_img(img_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)  # Reshape to (1, height, width, channels)\n",
    "\n",
    "        # Save the original image\n",
    "        original_image_name = f\"{image_index:03}.jpg\"\n",
    "        original_image_path = os.path.join(save_folder, original_image_name)\n",
    "        img.save(original_image_path)\n",
    "        image_index += 1\n",
    "\n",
    "        # Generate exactly 5 augmented versions for each original image\n",
    "        augmented_count = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=save_folder, save_prefix='', save_format='jpg'):\n",
    "            augmented_count += 1\n",
    "            if augmented_count >= 5:  # Stop after 5 augmentations\n",
    "                break\n",
    "\n",
    "    # Create the \"celebrities_all\" folder and copy the original images\n",
    "    final_save_folder = os.path.join(all_output_path, celeb)\n",
    "    os.makedirs(final_save_folder, exist_ok=True)\n",
    "\n",
    "    # Copy the original images (1-100) to the \"celebrities_all\" folder\n",
    "    for image_name in images:\n",
    "        original_image_path = os.path.join(celeb_folder, image_name)\n",
    "        final_image_path = os.path.join(final_save_folder, f\"{int(image_name.split('.')[0]):03}.jpg\")\n",
    "        shutil.copy2(original_image_path, final_image_path)\n",
    "\n",
    "    # Verify face detection in the augmented images\n",
    "    face_detected_images = []\n",
    "    for filename in sorted(os.listdir(save_folder)):\n",
    "        file_path = os.path.join(save_folder, filename)\n",
    "        if detect_face(file_path):\n",
    "            face_detected_images.append(file_path)\n",
    "\n",
    "    print(f\"{celeb} - Found {len(face_detected_images)} augmented images with detected faces.\")\n",
    "\n",
    "    # Ensure that we copy exactly 300 face-detected augmented images to the final folder\n",
    "    if len(face_detected_images) < 300:\n",
    "        print(f\"Warning: {celeb} only has {len(face_detected_images)} face-detected augmented images.\")\n",
    "        # If there are fewer than 300 valid images, we will just use whatever we have\n",
    "        face_detected_images = face_detected_images[:300]\n",
    "\n",
    "    # Copy the first 300 images with detected faces to the \"celebrities_all\" folder\n",
    "    for idx, image_path in enumerate(face_detected_images[:300]):\n",
    "        new_image_name = f\"{101 + idx:03}.jpg\"  # Naming from 101 to 400\n",
    "        new_image_path = os.path.join(final_save_folder, new_image_name)\n",
    "        shutil.copy2(image_path, new_image_path)\n",
    "\n",
    "    # Ensure the final number of images is exactly 400\n",
    "    total_images = len(os.listdir(final_save_folder))\n",
    "    if total_images != 400:\n",
    "        print(f\"Warning: {celeb} folder has {total_images} images, expected 400.\")\n",
    "\n",
    "print(\"Image augmentation and organization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SZA's folder was short some images. Let's correct this by implementing a separate for-loop to populate images for the SZA folder in celebrities_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 original images and 300 augmented images with detected faces in /workspace/DS4002Project3/DATA/celebrities_all/SZA.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# Set paths\n",
    "base_path = \"/workspace/DS4002Project3/DATA/celebrities/SZA\"  # Original SZA image folder\n",
    "extra_path = \"/workspace/DS4002Project3/DATA/celebrities_extra/SZA\"  # Path for augmented images\n",
    "final_path = \"/workspace/DS4002Project3/DATA/celebrities_all/SZA\"  # Path for final 400 images\n",
    "\n",
    "# Function to clear contents of a directory\n",
    "def clear_directory(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  # Remove the entire folder and its contents\n",
    "    os.makedirs(path, exist_ok=True)  # Recreate the empty folder\n",
    "\n",
    "# Clear out existing contents in the directories\n",
    "clear_directory(extra_path)\n",
    "clear_directory(final_path)\n",
    "\n",
    "# Copy original images to the final folder\n",
    "original_images = [img for img in os.listdir(base_path) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "for idx, image_name in enumerate(sorted(original_images)):\n",
    "    img_path = os.path.join(base_path, image_name)\n",
    "    new_img_name = f\"{idx + 1:03}.jpg\"  # Format with leading zeros (001.jpg, 002.jpg, ..., 100.jpg)\n",
    "    new_img_path = os.path.join(final_path, new_img_name)\n",
    "    shutil.copy(img_path, new_img_path)\n",
    "\n",
    "# Data augmentation settings (same as the ones used before)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented images\n",
    "for image_name in original_images:\n",
    "    img_path = os.path.join(base_path, image_name)\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    # Generate 8 versions per original image\n",
    "    augmented_count = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir=extra_path, save_prefix='', save_format='jpg'):\n",
    "        augmented_count += 1\n",
    "        if augmented_count >= 8:\n",
    "            break\n",
    "\n",
    "# Function to detect if an image contains a face\n",
    "def contains_face(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    faces = mtcnn(img)\n",
    "    return faces is not None\n",
    "\n",
    "# Collect the first 300 images with faces detected\n",
    "saved_count = 0\n",
    "for img_name in sorted(os.listdir(extra_path)):\n",
    "    if img_name.endswith('.jpg') and saved_count < 300:\n",
    "        img_path = os.path.join(extra_path, img_name)\n",
    "        if contains_face(img_path):\n",
    "            new_img_name = f\"{saved_count + 101:03}.jpg\"  # Start numbering from 101 (101.jpg, 102.jpg, ..., 400.jpg)\n",
    "            new_img_path = os.path.join(final_path, new_img_name)\n",
    "            Image.open(img_path).save(new_img_path)\n",
    "            saved_count += 1\n",
    "\n",
    "# Confirm the number of saved images\n",
    "print(f\"Saved {len(original_images)} original images and {saved_count} augmented images with detected faces in {final_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
